---
- hosts: all
  tasks:

    - name: create directory
      file: path={{ item }} state=directory owner=spark group=hadoop
      tags: install
      with_items:
        - /data/logs/spark2

    - name: copy spark tar file to remote host
      shell: ncftpget -z -ubigdata -p'whaley!90365' 10.255.130.6 /tmp bigdata/{{ item }}
      tags: install
      with_items:
        - spark-2.1.0-bin-hadoop2.6.2.tgz

    - name: tar spark tar to /app
      shell: cd /tmp && tar zxvf  spark-2.1.0-bin-hadoop2.6.2.tgz  -C /app
      tags: install
      args:
        creates: /app/spark-2.1.0-bin-hadoop2.6.2/.install

    - name: owner to spark
      shell: chown -R spark:hadoop /app/spark-2.1.0-bin-hadoop2.6.2
      tags: install
      args:
        creates: /app/spark-2.1.0-bin-hadoop2.6.2/.install

    - name: /app/spark-2.1.0-bin-hadoop2.6.2 owner to spark
      file: name=/app/spark-2.1.0-bin-hadoop2.6.2 owner=spark group=hadoop
      tags: install

    - name: create Create a soft link to spark
      file: src={{ item.src }} dest={{ item.dest }} state=link owner=spark group=hadoop
      tags: install
      with_items:
        - { src: '/app/spark-2.1.0-bin-hadoop2.6.2', dest: '/opt/spark2' }

    - name: touch install file
      shell: touch /app/spark-2.1.0-bin-hadoop2.6.2/.install
      tags: install
      args:
        creates: /app/spark-2.1.0-bin-hadoop2.6.2/.install

    - name: copy spark config file to remote host
      copy: src=/data/tools/ansible/modules/spark/config/spark2.1.0/{{ item }} dest=/opt/spark2/conf/{{ item }} owner=spark group=hadoop mode=0771
      tags: config
      with_items:
        - slaves
        - hive-site.xml
        - spark-defaults.conf
        - spark-env.sh
        - spark-thrift-sparkconf.conf
        - log4j.properties

    - name: copy launch file
      copy: src=/data/tools/ansible/modules/spark/config/spark2.1.0/{{ item }} dest=/opt/spark2/sbin/{{ item }} owner=spark group=hadoop mode=0771
      tags: config_launch
      with_items:
        - launch-thriftserver.sh