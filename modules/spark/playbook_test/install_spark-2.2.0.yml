---
- hosts: all
  tasks:

    - name: create directory
      file: path={{ item }} state=directory owner=spark group=hadoop
      tags: install
      with_items:
        - /data/logs/spark220

    - name: copy spark tar file to remote host
      shell: ncftpget -z -ubigdata -p'whaley!90365' 10.255.130.6 /tmp bigdata/{{ item }}
      tags: install
      with_items:
        - spark-2.2.0-bin-hadoop2.6.2.tgz

    - name: tar spark tar to /app
      shell: cd /tmp && tar zxvf  spark-2.2.0-bin-hadoop2.6.2.tgz  -C /app
      tags: install
      args:
        creates: /app/spark-2.2.0-bin-hadoop2.6.2/.install

    - name: owner to spark
      shell: chown -R spark:hadoop /app/spark-2.2.0-bin-hadoop2.6.2
      tags: install
      args:
        creates: /app/spark-2.2.0-bin-hadoop2.6.2/.install

    - name: /app/spark-2.2.0-bin-hadoop2.6.2 owner to spark
      file: name=/app/spark-2.2.0-bin-hadoop2.6.2 owner=spark group=hadoop
      tags: install

    - name: create Create a soft link to spark
      file: src={{ item.src }} dest={{ item.dest }} state=link owner=spark group=hadoop
      tags: install
      with_items:
        - { src: '/app/spark-2.2.0-bin-hadoop2.6.2', dest: '/opt/spark220' }

    - name: touch install file
      shell: touch /app/spark-2.2.0-bin-hadoop2.6.2/.install
      tags: install
      args:
        creates: /app/spark-2.2.0-bin-hadoop2.6.2/.install

    - name: copy spark sql lib file to remote host
      copy: src=/data/tools/ansible/modules/spark/config_test/spark2.2.0/lib/{{ item }} dest=/opt/spark220/jars/{{ item }} owner=spark group=hadoop mode=0644
      tags: config
      with_items:
        - spark-sql_2.11-2.2.0.jar
