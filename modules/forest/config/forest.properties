#processor class names which was seperated by ','
#forest.processor.chain1=cn.whaley.turbo.forest.processors.LogVerificationProcessor,cn.whaley.turbo.forest.processors.DecoderProcessor,cn.whaley.turbo.forest.processors.FieldRenameProcessor,cn.whaley.turbo.forest.processors
#.InfoReviseProcessor,cn.whaley.turbo.forest.processors.FormattingProcessor,cn.whaley.turbo.forest.processors
#.Write2KafkaProducerProcessor
#forest.processor.chain2=cn.whaley.turbo.forest.processors.LogVerificationProcessor,cn.whaley.turbo.forest.processors
#.Write2KafkaProducerProcessor
#For producer and consumer mutual
#Kafka cluster
medusa.get.processor.chain=cn.whaley.turbo.forest.processors.DecoderProcessor,cn.whaley.turbo.forest.processors.FormattingProcessor,cn.whaley.turbo.forest.processors.Write2KafkaProducerNewProcessor
medusa.post.processor.chain=cn.whaley.turbo.forest.processors.LogVerificationProcessor,cn.whaley.turbo.forest.processors.FormattingProcessor,cn.whaley.turbo.forest.processors.LogFlatteningProcessor,cn.whaley.turbo.forest.processors.Write2KafkaProducerNewProcessor
helios.get.processor.chain=cn.whaley.turbo.forest.processors.DecoderProcessor,cn.whaley.turbo.forest.processors.FieldRenameProcessor,cn.whaley.turbo.forest.processors.InfoReviseProcessor,cn.whaley.turbo.forest.processors.FormattingProcessor,cn.whaley.turbo.forest.processors.LogFlatteningProcessor,cn.whaley.turbo.forest.processors.PlayQosProcessor,cn.whaley.turbo.forest.processors.Write2KafkaProducerNewProcessor
helios.post.processor.chain=cn.whaley.turbo.forest.processors.LogVerificationProcessor,cn.whaley.turbo.forest.processors.FieldRenameProcessor,cn.whaley.turbo.forest.processors.InfoReviseProcessor,cn.whaley.turbo.forest.processors.FormattingProcessor,cn.whaley.turbo.forest.processors.LogFlatteningProcessor,cn.whaley.turbo.forest.processors.PlayQosProcessor,cn.whaley.turbo.forest.processors.Write2KafkaProducerNewProcessor
thor.probe.processor.chain=cn.whaley.turbo.forest.processors.ThorProbeWrite2KafkaProducerProcessor2
medusa.playqos.processor.chain=cn.whaley.turbo.forest.processors.MedusaPlayqosWrite2KafkaProducerProcessor

forest.topic=heliosLog
forest.noneed.process.log=activitylog
formattingprocessor.longtype.key=accountId,duration,speed,size,preMemory,postMemory
log.verification.version=01
# kafka for new api
#forest.bootstrap.servers=115.231.96.78:9092,115.231.96.80:9092,115.231.96.81:9092
#forest.bootstrap.servers=bigdata-computing-01-001:9092,bigdata-computing-01-003:9092,bigdata-computing-01-004:9092
forest.bootstrap.servers=bigdata-appsvr-130-1:9094,bigdata-appsvr-130-2:9094,bigdata-appsvr-130-3:9094,bigdata-appsvr-130-4:9094,bigdata-appsvr-130-5:9094,bigdata-appsvr-130-6:9094
forest.enable.auto.commit=true
forest.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
forest.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
forest.key.serializer=org.apache.kafka.common.serialization.StringSerializer
forest.value.serializer=org.apache.kafka.common.serialization.StringSerializer
etl.consumer.auto.commit.interval.ms=10000
etl.consumer.session.timeout.ms=30000
etl.consumer.group.id=etl-helios-group-deconstruction
etl.consumer.medusa.group.id=etl-medusa-group-deconstruction
etl.consumer.helios.poll.time.ms=1000
etl.consumer.max.poll.records=1000
#auto.offset.reset=largest
#etlçš„topics
data.storage.consumer.auto.commit.interval.ms=1000
data.storage.consumer.group.id=datastorage
data.storage.consumer.session.timeout.ms=30000
write2kafka.acks=all
write2kafka.retries=2
write2kafka.batch.size=10
write2kafka.linger.ms=1
write2kafka.buffer.memory=33554432
# For old api
# Common
kafka.zookeeper.connect=bigdata-computing-02-015:2182,bigdata-computing-02-016:2182,bigdata-computing-02-017:2182,bigdata-computing-02-018:2182,bigdata-computing-02-019:2182
kafka.metadata.broker.list=bigdata-computing-02-020:9092,bigdata-computing-02-021:9092,bigdata-computing-02-022:9092,bigdata-computing-02-023:9092,bigdata-computing-02-024:9092
#kafka.zookeeper.connect=10.10.2.15:2182,10.10.2.16:2182,10.10.2.17:2182,10.10.2.18:2182,10.10.2.19:2182
#kafka.metadata.broker.list=10.10.2.20:9092,10.10.2.21:9092,10.10.2.22:9092,10.10.2.23:9092,10.10.2.24:9092
kafka.zookeeper.seesion.timeout.ms=40000
kafka.zookeeper.sync.time.ms=2000
kafka.zookeeper.rebalance.max.retries=10
kafka.zookeeper.rebalance.backoff.ms=2000
# For ETLConsumer
etl.consumer.thread.num=8
helios.etl.consumer.topic=helios-pre-log
medusa.etl.consumer.topic=medusa-pre-log
medusa.etl.out.topic=medusa-processed-log
helios.etl.out.topic=helios-processed-log
medusa.test.etl.consumer.topic=medusa-pre-test-log
medusa.test.etl.out.topic=medusa-processed-test-log
helios.test.etl.consumer.topic=helios-pre-test-log
helios.test.etl.out.topic=helios-processed-test-log

# For DataStorageConsumer
ds.consumer.topics=helios
ds.consumer.thread.num=1
# For W2KafkaProduce
w2kafka.producer.serializer.class=kafka.serializer.StringEncoder
w2kafka.producer.partitioner.class=kafka.producer.DefaultPartitioner
w2kafka.request.acks=1

#kafka.metadata.broker.list.kylin=bigdata-appsvr-130-1:9094,bigdata-appsvr-130-2:9094,bigdata-appsvr-130-3:9094,bigdata-appsvr-130-4:9094,bigdata-appsvr-130-5:9094,bigdata-appsvr-130-6:9094
thor.probe.consumer.input.topic=helios-processed-log
thor.probe.out.topic=thor-probe-log
thor.probe.consumer.group.id=thor_probe

#medusa playqos
medusa.playqos.consumer.input.topic=medusa-processed-log
medusa.playqos.out.topic=medusa-playqos-output-product
medusa.playqos.consumer.group.id=medusa-playqos-group-product

#nginx medusa
nginx.medusa.etl.consumer.topic=log-raw-boikgpokn78sb95ktmsc1bnkechpgj9l
nginx.medusa.etl.out.topic=medusa-processed-log
nginx.medusa.etl.consumer.thread.num=8
nginx.etl.consumer.medusa.poll.time.ms=1000
nginx.etl.consumer.medusa.group.id=medusa-processed-log-product-20171009-group

#nginx helios
nginx.helios.etl.consumer.topic=log-raw-boikgpokn78sb95kjhfrendo8dc5mlsr
nginx.helios.etl.out.topic=helios-processed-log
nginx.helios.etl.consumer.thread.num=8
nginx.etl.consumer.helios.poll.time.ms=1000
nginx.etl.consumer.helios.group.id=helios-processed-log-product-20171009-group

