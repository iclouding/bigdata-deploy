---
- hosts: all
  tasks:
    - name: create medusa log directory
      file: path={{ item }} state=directory owner=spark group=hadoop
      tags: install
      with_items:
        - /app/dw/etl
        - /data/logs/dw

    - name: copy package to remote host
      shell: ncftpget -z -ubigdata -p'whaley!90365' 10.255.130.6 /tmp bigdata/{{ item }}
      tags: install
      with_items:
        - etl.tar.gz

    - name: decompress package
      shell: cd /tmp && tar zxvf etl.tar.gz -C /app/dw && chown -R spark:hadoop /app/dw/etl
      tags: install
      args:
        creates: /app/dw/etl/.install

    - name: create a soft link
      file: src=/app/dw dest=/opt/dw state=link owner=spark group=hadoop
      tags: install

    - name: touch install file
      shell: touch /app/dw/etl/.install
      tags: install
      args:
        creates: /app/dw/etl/.install

    - name: copy config file to remote host
      copy: src=/data/tools/ansible/modules/dw/etl/config/{{ item }} dest=/app/dw/etl/{{ item }} owner=spark group=hadoop mode=0771
      tags: config
      with_items:
          - conf/log4j.properties
          - conf/spark.properties
